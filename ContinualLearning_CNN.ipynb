{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv('sign_mnist_train.csv')\n",
    "test_df=pd.read_csv('sign_mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27455.000000</td>\n",
       "      <td>27455.000000</td>\n",
       "      <td>27455.000000</td>\n",
       "      <td>27455.000000</td>\n",
       "      <td>27455.000000</td>\n",
       "      <td>27455.000000</td>\n",
       "      <td>27455.000000</td>\n",
       "      <td>27455.000000</td>\n",
       "      <td>27455.000000</td>\n",
       "      <td>27455.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>27455.000000</td>\n",
       "      <td>27455.000000</td>\n",
       "      <td>27455.000000</td>\n",
       "      <td>27455.000000</td>\n",
       "      <td>27455.000000</td>\n",
       "      <td>27455.000000</td>\n",
       "      <td>27455.000000</td>\n",
       "      <td>27455.000000</td>\n",
       "      <td>27455.000000</td>\n",
       "      <td>27455.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.318813</td>\n",
       "      <td>145.419377</td>\n",
       "      <td>148.500273</td>\n",
       "      <td>151.247714</td>\n",
       "      <td>153.546531</td>\n",
       "      <td>156.210891</td>\n",
       "      <td>158.411255</td>\n",
       "      <td>160.472154</td>\n",
       "      <td>162.339683</td>\n",
       "      <td>163.954799</td>\n",
       "      <td>...</td>\n",
       "      <td>141.104863</td>\n",
       "      <td>147.495611</td>\n",
       "      <td>153.325806</td>\n",
       "      <td>159.125332</td>\n",
       "      <td>161.969259</td>\n",
       "      <td>162.736696</td>\n",
       "      <td>162.906137</td>\n",
       "      <td>161.966454</td>\n",
       "      <td>161.137898</td>\n",
       "      <td>159.824731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.287552</td>\n",
       "      <td>41.358555</td>\n",
       "      <td>39.942152</td>\n",
       "      <td>39.056286</td>\n",
       "      <td>38.595247</td>\n",
       "      <td>37.111165</td>\n",
       "      <td>36.125579</td>\n",
       "      <td>35.016392</td>\n",
       "      <td>33.661998</td>\n",
       "      <td>32.651607</td>\n",
       "      <td>...</td>\n",
       "      <td>63.751194</td>\n",
       "      <td>65.512894</td>\n",
       "      <td>64.427412</td>\n",
       "      <td>63.708507</td>\n",
       "      <td>63.738316</td>\n",
       "      <td>63.444008</td>\n",
       "      <td>63.509210</td>\n",
       "      <td>63.298721</td>\n",
       "      <td>63.610415</td>\n",
       "      <td>64.396846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>125.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>182.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>204.000000</td>\n",
       "      <td>204.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label        pixel1        pixel2        pixel3        pixel4  \\\n",
       "count  27455.000000  27455.000000  27455.000000  27455.000000  27455.000000   \n",
       "mean      12.318813    145.419377    148.500273    151.247714    153.546531   \n",
       "std        7.287552     41.358555     39.942152     39.056286     38.595247   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        6.000000    121.000000    126.000000    130.000000    133.000000   \n",
       "50%       13.000000    150.000000    153.000000    156.000000    158.000000   \n",
       "75%       19.000000    174.000000    176.000000    178.000000    179.000000   \n",
       "max       24.000000    255.000000    255.000000    255.000000    255.000000   \n",
       "\n",
       "             pixel5        pixel6        pixel7        pixel8        pixel9  \\\n",
       "count  27455.000000  27455.000000  27455.000000  27455.000000  27455.000000   \n",
       "mean     156.210891    158.411255    160.472154    162.339683    163.954799   \n",
       "std       37.111165     36.125579     35.016392     33.661998     32.651607   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%      137.000000    140.000000    142.000000    144.000000    146.000000   \n",
       "50%      160.000000    162.000000    164.000000    165.000000    166.000000   \n",
       "75%      181.000000    182.000000    183.000000    184.000000    185.000000   \n",
       "max      255.000000    255.000000    255.000000    255.000000    255.000000   \n",
       "\n",
       "       ...      pixel775      pixel776      pixel777      pixel778  \\\n",
       "count  ...  27455.000000  27455.000000  27455.000000  27455.000000   \n",
       "mean   ...    141.104863    147.495611    153.325806    159.125332   \n",
       "std    ...     63.751194     65.512894     64.427412     63.708507   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...     92.000000     96.000000    103.000000    112.000000   \n",
       "50%    ...    144.000000    162.000000    172.000000    180.000000   \n",
       "75%    ...    196.000000    202.000000    205.000000    207.000000   \n",
       "max    ...    255.000000    255.000000    255.000000    255.000000   \n",
       "\n",
       "           pixel779      pixel780      pixel781      pixel782      pixel783  \\\n",
       "count  27455.000000  27455.000000  27455.000000  27455.000000  27455.000000   \n",
       "mean     161.969259    162.736696    162.906137    161.966454    161.137898   \n",
       "std       63.738316     63.444008     63.509210     63.298721     63.610415   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%      120.000000    125.000000    128.000000    128.000000    128.000000   \n",
       "50%      183.000000    184.000000    184.000000    182.000000    182.000000   \n",
       "75%      208.000000    207.000000    207.000000    206.000000    204.000000   \n",
       "max      255.000000    255.000000    255.000000    255.000000    255.000000   \n",
       "\n",
       "           pixel784  \n",
       "count  27455.000000  \n",
       "mean     159.824731  \n",
       "std       64.396846  \n",
       "min        0.000000  \n",
       "25%      125.500000  \n",
       "50%      182.000000  \n",
       "75%      204.000000  \n",
       "max      255.000000  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train_df dataset consit of 1st column representing labels 1 to 24. The label is loaded in a seperate dataframe called 'train_label' and the 'label' column is dropped from the original training dataframe which now consist of only 784 pixel values for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract labels and features\n",
    "y_train = train_df['label']\n",
    "X_train = train_df.drop(columns=['label'])\n",
    "\n",
    "y_test = test_df['label']\n",
    "X_test = test_df.drop(columns=['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split dataset based on label ranges\n",
    "def split_dataset(X, y):\n",
    "    # Convert to DataFrame for easy indexing\n",
    "    X = pd.DataFrame(X)\n",
    "    y = pd.Series(y)\n",
    "\n",
    "    # Define label ranges\n",
    "    mask1 = (y >= 0) & (y <= 7)\n",
    "    mask2 = (y > 7) & (y <= 13)\n",
    "    mask3 = (y > 13) & (y <= 24)\n",
    "\n",
    "    # Split data\n",
    "    X_set1, y_set1 = X[mask1], y[mask1]\n",
    "    X_set2, y_set2 = X[mask2], y[mask2]\n",
    "    X_set3, y_set3 = X[mask3], y[mask3]\n",
    "\n",
    "    return (X_set1, y_set1), (X_set2, y_set2), (X_set3, y_set3)\n",
    "\n",
    "# Apply the function to training data\n",
    "(X_train_1, y_train_1), (X_train_2, y_train_2), (X_train_3, y_train_3) = split_dataset(X_train, y_train)\n",
    "\n",
    "# Apply the function to test data\n",
    "(X_test_1, y_test_1), (X_test_2, y_test_2), (X_test_3, y_test_3) = split_dataset(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to NumPy array and reshape\n",
    "X_train_1 = X_train_1.to_numpy().reshape(-1, 28, 28, 1)\n",
    "X_test_1 = X_test_1.to_numpy().reshape(-1, 28, 28, 1)\n",
    "\n",
    "X_train_2 = X_train_2.to_numpy().reshape(-1, 28, 28, 1)\n",
    "X_test_2 = X_test_2.to_numpy().reshape(-1, 28, 28, 1)\n",
    "\n",
    "X_train_3 = X_train_3.to_numpy().reshape(-1, 28, 28, 1)\n",
    "X_test_3 = X_test_3.to_numpy().reshape(-1, 28, 28, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Ensure labels are within the correct range (0-23)\n",
    "y_train_1 = to_categorical(y_train_1 - 1, num_classes=24)\n",
    "y_test_1 = to_categorical(y_test_1 - 1, num_classes=24)\n",
    "y_train_2 = to_categorical(y_train_2 - 1, num_classes=24)\n",
    "y_test_2 = to_categorical(y_test_2 - 1, num_classes=24)\n",
    "y_train_3 = to_categorical(y_train_3 - 1, num_classes=24)\n",
    "y_test_3 = to_categorical(y_test_3 - 1, num_classes=24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.5, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Architechture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sunka\\Desktop\\Hand_Gesture_Recognition_Using_ContinualLearning_CNN\\myenv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">750</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,275</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">205,312</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,312</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m75\u001b[0m)     │           \u001b[38;5;34m750\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m75\u001b[0m)     │           \u001b[38;5;34m300\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m75\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m)     │        \u001b[38;5;34m33,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m)     │           \u001b[38;5;34m200\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m50\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m25\u001b[0m)       │        \u001b[38;5;34m11,275\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m25\u001b[0m)       │           \u001b[38;5;34m100\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m25\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m205,312\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │        \u001b[38;5;34m12,312\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">264,049</span> (1.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m264,049\u001b[0m (1.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">263,749</span> (1.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m263,749\u001b[0m (1.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">300</span> (1.17 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m300\u001b[0m (1.17 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(75 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (28,28,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(50 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(25 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 512 , activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units = 24 , activation = 'softmax'))\n",
    "model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EWC for Continual Learning Implementation\n",
    "\n",
    "Split Data: Divide the dataset into three subsets:\n",
    "\n",
    "Subset 1: Labels 0-7\n",
    "Subset 2: Labels 7-13\n",
    "Subset 3: Labels 13-24\n",
    "Train Sequentially with EWC:\n",
    "\n",
    "Train the model on Subset 1, compute Fisher Information Matrix (FIM), and save important weights.\n",
    "Apply EWC loss when training on Subset 2, preventing drastic changes to important weights.\n",
    "Repeat the process for Subset 3.\n",
    "\n",
    "\n",
    "Train the model on the first subset and compute the Fisher Information Matrix (FIM).\n",
    "Store the important parameters learned in the first task.\n",
    "Apply EWC penalty when training on the second subset.\n",
    "Repeat the process for the third subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "class EWC:\n",
    "    def __init__(self, model, dataset, labels, lambda_ewc=0.1):\n",
    "        self.model = model\n",
    "        self.dataset = dataset\n",
    "        self.labels = labels  # Initialize labels\n",
    "        self.labels = tf.convert_to_tensor(self.labels, dtype=tf.float32)  \n",
    "        self.lambda_ewc = lambda_ewc\n",
    "        self.fisher_information = {}\n",
    "        self.optimal_params = {}\n",
    "\n",
    "    def compute_fisher_information(self):\n",
    "        \"\"\"Compute the Fisher Information for each parameter in the model\"\"\"\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.model(self.dataset, training=True)\n",
    "            sparse_labels = tf.argmax(self.labels, axis=1)  # Convert one-hot to class indices\n",
    "            loss = tf.keras.losses.sparse_categorical_crossentropy(sparse_labels, predictions, from_logits=False)\n",
    "\n",
    "\n",
    "        grads = tape.gradient(loss, self.model.trainable_variables)\n",
    "        \n",
    "        for var, grad in zip(self.model.trainable_variables, grads):\n",
    "            if grad is not None:\n",
    "                fisher_value = tf.square(grad)  # Approximation of Fisher Information\n",
    "                self.fisher_information[var.name] = fisher_value\n",
    "                self.optimal_params[var.name] = var.numpy()\n",
    "\n",
    "    def ewc_loss(self):\n",
    "        \"\"\"Compute the EWC penalty\"\"\"\n",
    "        penalty = 0\n",
    "        for var in self.model.trainable_variables:\n",
    "            if var.name in self.fisher_information:\n",
    "                penalty += tf.reduce_sum(self.fisher_information[var.name] * tf.square(var - self.optimal_params[var.name]))\n",
    "\n",
    "        return self.lambda_ewc * penalty\n",
    "\n",
    "    def apply_ewc(self, loss):\n",
    "        \"\"\"Modify the loss function with EWC penalty\"\"\"\n",
    "        return loss + self.ewc_loss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sunka\\Desktop\\Hand_Gesture_Recognition_Using_ContinualLearning_CNN\\myenv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 43ms/step - accuracy: 0.5369 - loss: 1.3715 - val_accuracy: 0.7067 - val_loss: 0.8681 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.8997 - loss: 0.2686 - val_accuracy: 0.8665 - val_loss: 0.3134 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.9423 - loss: 0.1579 - val_accuracy: 0.9603 - val_loss: 0.0926 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - accuracy: 0.9719 - loss: 0.0823 - val_accuracy: 0.8683 - val_loss: 0.3632 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - accuracy: 0.9702 - loss: 0.0814 - val_accuracy: 0.9881 - val_loss: 0.0340 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - accuracy: 0.9795 - loss: 0.0592 - val_accuracy: 0.9849 - val_loss: 0.0402 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9866 - loss: 0.0388\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 0.9866 - loss: 0.0388 - val_accuracy: 0.9845 - val_loss: 0.0273 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 46ms/step - accuracy: 0.9892 - loss: 0.0328 - val_accuracy: 0.9961 - val_loss: 0.0093 - learning_rate: 5.0000e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 50ms/step - accuracy: 0.9933 - loss: 0.0192 - val_accuracy: 0.9989 - val_loss: 0.0075 - learning_rate: 5.0000e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.9926 - loss: 0.0217 - val_accuracy: 0.9965 - val_loss: 0.0072 - learning_rate: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,      # Rotate images by 15 degrees\n",
    "    width_shift_range=0.1,  # Shift width by 10%\n",
    "    height_shift_range=0.1, # Shift height by 10%\n",
    "    shear_range=0.1,        # Apply shear transformation\n",
    "    zoom_range=0.1,         # Random zoom\n",
    "    horizontal_flip=True,   # Flip images horizontally\n",
    "    brightness_range=[0.8, 1.2],  # Adjust brightness\n",
    "    fill_mode='nearest'     # Fill in missing pixels\n",
    ")\n",
    "\n",
    "# Train on the first subset with augmentation\n",
    "ewc = EWC(model, X_train_1, y_train_1, lambda_ewc=0.1)\n",
    "\n",
    "# Fit model using augmented data\n",
    "train_generator_1 = datagen.flow(X_train_1, y_train_1, batch_size=32)\n",
    "model.fit(train_generator_1, validation_data=(X_test_1, y_test_1), epochs=10, callbacks=[learning_rate_reduction])\n",
    "\n",
    "# Compute Fisher Information\n",
    "ewc.compute_fisher_information()\n",
    "\n",
    "# Train on the second subset with EWC penalty and augmentation\n",
    "train_generator_2 = datagen.flow(X_train_2, y_train_2, batch_size=32)\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    base_loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
    "    return ewc.apply_ewc(base_loss)\n",
    "\n",
    "model.compile(optimizer=Adam(), loss=custom_loss, metrics=['accuracy'])\n",
    "model.fit(train_generator_2, validation_data=(X_test_2, y_test_2), epochs=10, callbacks=[learning_rate_reduction])\n",
    "\n",
    "# Compute Fisher Information again\n",
    "ewc.compute_fisher_information()\n",
    "\n",
    "# Train on the third subset with EWC penalty and augmentation\n",
    "train_generator_3 = datagen.flow(X_train_3, y_train_3, batch_size=32)\n",
    "model.fit(train_generator_3, validation_data=(X_test_3, y_test_3), epochs=10, callbacks=[learning_rate_reduction])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance on the first test subset\n",
    "test_loss_1, test_accuracy_1 = model.evaluate(X_test_1, y_test_1)\n",
    "print(f\"Test Accuracy on Set 1: {test_accuracy_1:.4f}\")\n",
    "\n",
    "# Evaluate model performance on the second test subset\n",
    "test_loss_2, test_accuracy_2 = model.evaluate(X_test_2, y_test_2)\n",
    "print(f\"Test Accuracy on Set 2: {test_accuracy_2:.4f}\")\n",
    "\n",
    "# Evaluate model performance on the third test subset\n",
    "test_loss_3, test_accuracy_3 = model.evaluate(X_test_3, y_test_3)\n",
    "print(f\"Test Accuracy on Set 3: {test_accuracy_3:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Get predictions for each test set\n",
    "y_pred_1 = model.predict(X_test_1)\n",
    "y_pred_1_classes = y_pred_1.argmax(axis=1)\n",
    "y_test_1_classes = y_test_1.argmax(axis=1)\n",
    "\n",
    "y_pred_2 = model.predict(X_test_2)\n",
    "y_pred_2_classes = y_pred_2.argmax(axis=1)\n",
    "y_test_2_classes = y_test_2.argmax(axis=1)\n",
    "\n",
    "y_pred_3 = model.predict(X_test_3)\n",
    "y_pred_3_classes = y_pred_3.argmax(axis=1)\n",
    "y_test_3_classes = y_test_3.argmax(axis=1)\n",
    "\n",
    "# Print classification reports\n",
    "print(\"Classification Report for Test Set 1:\")\n",
    "print(classification_report(y_test_1_classes, y_pred_1_classes))\n",
    "\n",
    "print(\"Classification Report for Test Set 2:\")\n",
    "print(classification_report(y_test_2_classes, y_pred_2_classes))\n",
    "\n",
    "print(\"Classification Report for Test Set 3:\")\n",
    "print(classification_report(y_test_3_classes, y_pred_3_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to plot confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=range(24), yticklabels=range(24))\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Plot confusion matrices\n",
    "plot_confusion_matrix(y_test_1_classes, y_pred_1_classes, \"Confusion Matrix - Test Set 1\")\n",
    "plot_confusion_matrix(y_test_2_classes, y_pred_2_classes, \"Confusion Matrix - Test Set 2\")\n",
    "plot_confusion_matrix(y_test_3_classes, y_pred_3_classes, \"Confusion Matrix - Test Set 3\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
